# need prediction evaluation

prompt：
````
【System Prompt】
你是一个良好的打分器，可以按照要求为待测的助手模型生成的内容进行打分。
【User Prompt】
考虑用户与日常助手进行交互的场景，助手模型需要结合用户的个性化信息，针对用户当前的询问深入理解用户的隐式需求，并给出对于用户实际需求的描述。现在，给你用户的初始询问作为背景，同时给你待测模型的预测内容以及作为预测目标的用户实际需求参考内容，需要你将预测内容与参考内容进行对比，为模型的预测效果打分。

# 用户初始询问
"""
有没有什么办法可以让我更高效地完成每天的工作？
"""

# 用户实际需求（参考内容）
包含用户完整需求描述("requirement")以及用户的隐式需求列表("implicit_needs")两部分。其中用户的隐式需求列表包含2个条目，对应于用户在询问中未明确提及的2方面隐式需求内容。
"""
{
    "requirement": "用户希望找到一种能够适应其高强度工作节奏的时间管理方法，既能帮助他合理规划每日任务，又能尽量减少突发性事务对其效率的影响，从而确保重要工作按时完成。",
    "implicit_needs": ["需要一个适合自身工作节奏的时间规划工具", "减少外部干扰以集中精力处理重要任务"]
}
"""

# 待测模型预测内容
"""
用户希望找到一种方法来更有效地管理日常任务，如整理会议笔记、记录客户需求、撰写销售报告以及安排客户拜访等，以提高工作效率。
"""

# 评测要求及输出模板
## 评测要求
1. 输入中提供的“用户初始询问”仅作为背景，请着重关注预测内容与参考内容之间的匹配程度。
2. 在输入中给出的“用户实际需求”（即参考内容）中，用户完整需求描述("requirement")可以看作结合了隐式需求列表("implicit_needs")中两个条目的总体描述，可以作为预测内容的参考。但对于预测内容效果的评价应聚焦于预测内容与隐式需求列表中2个条目的匹配程度。
3. 评分范围为[0, 2]区间，如果预测内容能够匹配上参考内容中的2个条目，则记2分；如果预测内容只能匹配参考内容中的1个条目，则记1分；如果预测的条目未能匹配任何参考条目，则记0分。不考虑2条参考条目之间的顺序因素。
4. 在考虑预测内容与参考的隐式需求列表条目的匹配情况时，主要关注每个参考条目的核心要素是否在预测内容中得到了体现即可，不需要过分关注语言的匹配。如果预测内容的某部分描述属于某条参考内容所关注方面的更具体细节，可以认为两者在对应方面是匹配的。
5. 考虑到预测内容与某个参考条目可能存在部分匹配的情况，可以对部分匹配的条目记0.5分。
6. 需要按照下面的json格式输出模板给出输出，先用一段话给出对于当前样例评测的分析，随后给出待测模型的得分。

## 输出模板
"""
{
    "analysis": "...", // 评测分析
    "score": <分数> // 取值范围：{0, 0.5, 1, 1.5, 2}
}
"""

现在，请你按照要求给出评测分析和分数。
````

效果：
````
{
    "analysis": "在评测中，待测模型的预测内容主要聚焦于用户希望更有效地管理日常任务，如整理会议笔记、记录客户需求、撰写销售报告以及安排客户拜访等。然而，参考内容中的隐式需求包括需要一个适合自身工作节奏的时间规划工具和减少外部干扰以集中精力处理重要任务。预测内容并未明确提及时间规划工具或减少外部干扰的相关内容，因此未能直接匹配参考内容中的任何一条隐式需求。不过，预测内容中提到的管理日常任务可以部分关联到时间规划工具的使用，因此可以给予0.5分的部分匹配。",
    "score": 0.5
}
````